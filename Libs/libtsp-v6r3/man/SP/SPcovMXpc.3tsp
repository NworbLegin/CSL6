.TH SPcovMXpc 3tsp "TSP (libtsp/SP)"
.SH Routine
.in +4n
.ti -4n
double SPcovMXpc (const float *Cov[], float pc[], int Np)
.in -4n
.SH Purpose
.in +4n
.ti -4n
Find predictor coefficients using the modified covariance method
.in -4n
.SH Description
This procedure finds the predictor coefficients for a linear predictor using
the modified covariance method which guarantees a minimum phase prediction
error filter.
.PP
Consider a linear predictor with Np coefficients,
.ft CW
.nf
.ne 3
          Np
  y(k) = SUM p(i) x(k-i) ,
         i=1
.fi
.ft P
where x(i) is the input signal.  This procedure starts by solving for
predictors of increasing order as in the case of the standard covariance
method.  The modified covariance procedure calculates the ratio of the error
signal energies for predictors of successive orders.  In the autocorrelation
method the residual error energy for an n'th order predictor is given by
.ft CW
.nf
.ne 3
                n         2
  Perr(n) = Ex PROD [1 - k (i)],
               i=0
.fi
.ft P
where k(i) is a reflection coefficient.  In the modified covariance method,
the ratios of error energies for the covariance method solution are used to
determine the reflection coefficients.  The sign of k(i) is determined from
the sign of the i'th predictor coefficient.  The covariance method predictor
coefficients are discarded; instead a set of predictor coefficients is
derived from the reflection coefficients.  Since the error energy decreases
with predictor order, the reflection coefficients are less than unity in
magnitude.  This also means that the predictor coefficients derived from them
correspond to a minimum phase prediction error filter.
.PP
The equations for the standard covariance method are
.PP
.ft CW
.nf
.ne 3
  R p = r,
.fi
.ft P
.PP
where R is a symmetric positive definite covariance matrix, p is a vector
of filter coefficients and r is a vector of correlation values.  The matrix
R and and vector r are defined as follows
.PP
.ft CW
.nf
.ne 3
  R(i,j) = Cov(i,j) = E[x(k-i) x(k-j)],  for 1 <= i,j <= N,
    r(i) = Cov(0,i) = E[x(k) x(k-i)],    for 1 <= i <= N.
.fi
.ft P
.PP
The solution is found using a Cholesky decomposition of the matrix R.  The
resulting mean-square prediction error for the standard covariance method can
be expressed as
.PP
.ft CW
.nf
.ne 3
  perr = Ex - 2 p'r + p'R p
       = Ex - p'r ,
.fi
.ft P
.PP
where Ex is the mean-square value of the input signal,
.PP
.ft CW
.nf
.ne 3
  Ex = Cov(0,0) = E[x(k)^2].
.fi
.ft P
.PP
If the coefficient matrix is numerically not positive definite, or if the
prediction error energy becomes negative at some stage in the calculation,
the remaining predictor coefficients are set to zero.
.PP
The expectation operator E[.] is often replaced by a sum over k over a finite
interval.  Minimization of the prediction error over this interval defines
the so-called covariance method for determining the linear prediction
coefficients.
.PP
Predictor coefficients are usually expressed algebraically as vectors with
1-offset indexing.  The correspondence to the 0-offset C-arrays is as
follows.
.ft CW
.nf
.ne 3
  p(1) <==> pc[0]       predictor coefficient corresponding to lag 1
  p(i) <==> pc[i-1]     1 <= i < Np
.fi
.ft P
.SH Parameters
.in +4n
.ti -4n
<-  double SPcovXpc
.br
Resulting prediction error energy.  This is the prediction error for the
coefficients returned by this routine.
.ti -4n
 -> const float *Cov[]
.br
Cov is an array of pointers to the rows of an Np+1 by Np+1 symmetric
positive definite correlation matrix.  Only the lower triangular portion
of Cov is accessed.  Note that with ANSI C, if the actual parameter
is not declared to have the const attribute, an explicit cast to
(const float **) is required.
.ti -4n
<-  const float pc[]
.br
Np element vector of predictor coefficients.  Coefficient pc[i] is the
predictor coefficient corresponding to lag i+1.
.ti -4n
 -> int Np
.br
Number of predictor coefficients
.in -4n
.SH Author / revision
P. Kabal
/ Revision 1.10  2003/05/09
.SH See Also
SPcovXpc,
SPcovar,
libtsp
